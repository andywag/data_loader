basic:
  model: "multi-label"
  source:
    length: !iterations
      iterations: 32
    source: !huggingface
      dataset: "xed_en_fi"
      args: "en_annotated"
      operations: ["train"]
  tokenizer: 
    config: 
      batch_size: 32
      sequence_length: 384
      number_labels: 9
      tokenizer_name: "bert-base-uncased"
  transport:
    transport: !test
  node: !none
    
    

python_match:
  model: "multi-label"
  source:
    shuffle: false
    length: !epochs
      epochs: 1 
    source: !huggingface
      dataset: "xed_en_fi"
      args: "en_annotated"
      operations: ["train"]
  tokenizer: 
    config: 
      batch_size: 1024
      sequence_length: 96
      number_labels: 9
      tokenizer_name: "bert-base-uncased"
  transport:
    transport: !zmq
      address: "ipc:///tmp/emot_python_compare"
  node: !python
    command: "python3"
    cwd: "../python"
    args: ["emot_dataset_compare.py"]

zmq_ipc:
  model: "multi-label"
  source:
    flatten: true
    length: !epochs
      epochs: 6 
    source: !huggingface
      dataset: "xed_en_fi"
      args: "en_annotated"
      operations: ["train"]
  tokenizer: 
    config: 
      batch_size: 1024
      sequence_length: 96
      number_labels: 9
      tokenizer_name: "bert-base-uncased"
  transport:
    transport: !zmq
      address: "ipc:///tmp/multi-label"
  node: !none
    
     